# Build Custom GPT-4 or GPT-3.5 Code Interpreter

This is an example how to build a custom simple code interpreter using [OpenAI GPT-4](https://platform.openai.com/docs/models) and E2B. {{ className: 'lead' }}

## What is Code Interpreter?

[Code Interpreter](https://openai.com/blog/chatgpt-plugins?ref=blog.roboflow.com#code-interpreter) is a [ChatGPT plugin](https://platform.openai.com/docs/plugins/introduction) released by OpenAI that gives ChatGPT capabilites to run Python code.

This guide will show you how to build your own custom code interpreter using E2B and GPT-4. {{ className: 'lead' }}

You can find the final code in [this GitHub repository](/todo).

## Install E2B and OpenAI

First, install the required packages. We need to install the E2B package and OpenAI package.

<CodeGroup isRunnable={false}>
```bash {{ language: 'python' }}
pip install e2b
pip install openai
```

```bash {{ language: 'js' }}
npm i @e2b/sdk
npm i openai
```

</CodeGroup>

## Obtain API keys

Let's get our API keys for E2B and OpenAI. We'll need them to use the APIs.

1. Get your E2B API Key from [here](/getting-started/api-key)
2. Get your GPT-4 or GPT-3.5 at the [OpenAI website](https://platform.openai.com/)

## Import E2B and OpenAI

Now we need to import the packages we installed in the previous step.

<CodeGroup isRunnable={false}>
```python
import e2b
import openai
```

```js
import e2b from '@e2b/sdk'
import OpenAI from 'openai'
```

</CodeGroup>

## Set up OpenAI chat completion endpoint

Here we set up the OpenAI chat completion endpoint that allows to call the GPT-4 (or GPT-3.5) models.

<CodeGroup isRunnable={false}>
```python
response = openai.ChatCompletion.create(
  model="gpt-4", # Or use gpt-3.5-turbo
  messages=[
      {"role": "system", "content": "You are a senior developer that can code in Python."},
  ]
)
```

```js
const openai = new OpenAI()
const chatCompletion = await openai.chat.completions.create({
  model: 'gpt-4', // Or use 'gpt-3.5-turbo'
  messages: [
    {
      role: 'system',
      content: 'You are a senior developer that can code in Python.',
    },
  ],
})
```

</CodeGroup>

If you print the response, you should see something like this:

```json
{
  "id": "chatcmpl-846e96G7wm4s7dSqgWvnaPaanyQ3j",
  "object": "chat.completion",
  "created": 1695989553,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Great! How can I assist you today? Are you looking for help with Python solutions, or do you need some general advice about software development?"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 18,
    "completion_tokens": 29,
    "total_tokens": 47
  }
}
```

## Set up OpenAI functions for generating code

We're going to take an advantage of the [OpenAI functions](https://openai.com/blog/function-calling-and-other-api-updates). Defining these functions will make it easier instructing the model that it can write Python code to complete request from the user. We'll execute this code later using E2B.

<CodeGroup isRunnable={false}>
```python
functions = [
  {
      "name": "exec_code",
      "description": "Executes the passed Python code and returns the stdout and stderr.",
      "parameters": {
          "type": "object",
          "properties": {
              "code": {
                  "type": "string",
                  "description": "The python code to execute.",
              },
          },
          "required": ["code"],
      },
  }
]
```

```js
const functions = [
  {
    name: 'exec_code',
    description: 'Executes the passed Python code and returns the stdout and stderr.',
    parameters: {
      type: 'object',
      properties: {
        code: {
          type: 'string',
          description: 'The python code to execute.',
        },
      },
      required: ['code'],
    },
  },
]
```

</CodeGroup>

We created an OpenAI function `exec_code` that expects a single parameter `code`. The `code` parameter will be the Python code generated by GPT that we'll execute.

Now we pass the `functions` variable to the GPT call we made earlier and also add a few messages to show model how to use the `exec_code` function.
The new code is marked by the highlighted lines.

<CodeGroup isRunnable={false}>
```python
response = openai.ChatCompletion.create(
  model="gpt-4",
  messages=[
      {"role": "system", "content": "You are a senior developer that can code in Python."},
      {"role": "user", "content": "Write hello world"}, # $HighlightLine
      {"role": "assistant", "content": "print(\"hello world\")", "name":"exec_code"}, # $HighlightLine
      {"role": "user", "content": "Generate first 100 fibonacci numbers"}, # $HighlightLine
  ],
  functions=functions, # $HighlightLine
)
```

```js
const chatCompletion = await openai.chat.completions.create({
  model: 'gpt-4',
  messages: [
    {
      role: 'system',
      content: 'You are a senior developer that can code in Python.',
    },
    {
      role: 'user', // $HighlightLine
      content: 'Write hello world', // $HighlightLine
    },
    {
      role: 'assistant', // $HighlightLine
      content: 'print("hello world")', // $HighlightLine
      name: 'exec_code', // $HighlightLine
    },
    {
      role: 'user', // $HighlightLine
      content: 'Generate first 100 fibonacci numbers', // $HighlightLine
    },
  ],
  functions, // $HighlightLine
})
```

</CodeGroup>

If you print the GPT response now, you'll most likely see the model is calling the `exec_code` function we defined earlier and is passing code for generating fibonacci numbers in the first element of the `choices` JSON array.

```json
{
  ...
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "function_call": {
          "name": "exec_code",
          "arguments": "{\n  \"code\": \"def fibonacci(n):\\n    fib_sequence = [0, 1]\\n    while len(fib_sequence) < n:\\n        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\\n    return fib_sequence\\n\\nprint(fibonacci(100))\"\n}"
        }
      },
      "finish_reason": "function_call"
    }
  ]
}
```

## Parsing the GPT response

<CodeGroup isRunnable={false}>
```python
# Hello
print()
```

```js
// Hello
console.log()
```

</CodeGroup>

## Executing code GPT-generated code using E2B

It's time to actually run the code generated by GPT-4. We'll be using the `e2b.runCode`/`e2b.run_code` to execute the code in E2B's sandboxed playground.

## Advanced: Allow GPT to install missing packages

## Advanced: Allow GPT to fix itself

## Switch to
