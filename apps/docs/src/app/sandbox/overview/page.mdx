# Overview

The E2B's LLM sandboxes are isolated cloud environments for your AI apps. These LLM sandboxes are an ideal fit for building AI assistants like coding copilots, code interpreters, AI data analysts, AI browser assistants, and similar new kind of AI-powered apps.

Using the sandboxes allows for a secure way to run the unpredictable LLM-generated code and safe LLM tool usage.

Additionally, each running instance of your AI app can have its own separate sandbox without you worrying about any infrastructure provisioning, networking, or security.

## How sandboxes work under the hood

When you create a new sandbox session, we start a small VM in our cloud. This VM is running a Ubuntu OS and it takes about 400-600ms to start it.

Inside this sandbox, your AI app can [run code and start any programs](/sandbox/api/process), access the internet to download or upload data, use the [filesystem](/sandbox/api/filesystem), start long running processes such as web servers, and more.
You as a developer can also [upload](/sandbox/api/upload) to sandbox and [download](/sandbox/api/upload) from sandbox any file you want.

To start and control the LLM sandbox, use the [E2B SDK](/getting-started/installation) for Python or JavaScript.


<CodeGroupAutoload
  title="Starting LLM Sandbox"
  path="basics/init"
/>

<Note>
Make sure you have the `E2B_API_KEY` environment variable set with your [API key](/getting-started/api-key).
</Note>

{/*
## Next steps

TODO */}
